{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarizer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+ykxeU7gB+qRE9fOu8DVN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deregenboogm/NLP_coronavirus_project/blob/master/text-summarization/summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIAL_FKwi_8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_summary(text):\n",
        "  ## Data pre-processing\n",
        "  ### Removing square brackets and extra spaces\n",
        "  text = re.sub(r'\\[[0-9]*\\]', ' ', text)\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "  ### Removing special characters and digits\n",
        "  cleaned_text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "  cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
        "\n",
        "\n",
        "  ## Define a function to create the word frequency table\n",
        "  def word_frequency_table(cleaned_text):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    words = word_tokenize(cleaned_text)\n",
        "    pos_tag_words = nltk.pos_tag(words)\n",
        "    pos_tag_noun_verb = []\n",
        "    tags = [\"NN\", \"NNP\", \"NNS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]\n",
        "    for word,tag in pos_tag_words:\n",
        "        if tag in tags:\n",
        "          pos_tag_noun_verb.append(word)        \n",
        "    \n",
        "    frequency_table = {}\n",
        "    for word in pos_tag_noun_verb:\n",
        "      if word not in stop_words:\n",
        "        word = word = ps.stem(word)\n",
        "        if word in frequency_table:\n",
        "            frequency_table[word] += 1\n",
        "        else:\n",
        "            frequency_table[word] = 1 \n",
        "    \n",
        "    return frequency_table\n",
        "\n",
        "  ## Create the word frequency table\n",
        "  frequency_table= word_frequency_table(cleaned_text) \n",
        "\n",
        "  \n",
        "  ## Tokenize the sentences: Split the text in a list of sentences\n",
        "  list_of_sentences = sent_tokenize(text)\n",
        "\n",
        "\n",
        "  ## Define a function to create a sentence score table\n",
        "  def score_sentences(list_of_sentences, frequency_table):    \n",
        "    sentence_score_table = {}\n",
        "    for sentence in list_of_sentences:\n",
        "      number_of_words_in_sentence = len(sentence.split())\n",
        "      if number_of_words_in_sentence > 2 and number_of_words_in_sentence < 70:\n",
        "        for word in word_tokenize(sentence.lower()):          \n",
        "          for word in frequency_table:\n",
        "            if word in sentence.lower():                            \n",
        "              if sentence in sentence_score_table:                \n",
        "                sentence_score_table[sentence] += frequency_table[word] / number_of_words_in_sentence\n",
        "              else:\n",
        "                sentence_score_table[sentence] = frequency_table[word] / number_of_words_in_sentence\n",
        "    return sentence_score_table\n",
        "\n",
        "\n",
        "  ## Create a sentence score table \n",
        "  sentence_score_table = score_sentences(list_of_sentences, frequency_table)\n",
        "  \n",
        "\n",
        "  ## Define a function to create and limit the length of the summary\n",
        "  def summary(list_of_sentences, sentence_score_table):\n",
        "    # Sort sentences accoring to their values\n",
        "    sentences_sorted = dict(sorted(sentence_score_table.items(), key=operator.itemgetter(1),reverse=True))\n",
        "    sentences_sorted = list(sentences_sorted.keys())\n",
        "\n",
        "    # Limit the number of summary sentences with the highest scores\n",
        "    result = sentences_sorted[:3]\n",
        "           \n",
        "    # Collect the highest scored sentences\n",
        "    candiates_for_summary = \"\"  \n",
        "    for sentence in sentences_sorted:\n",
        "      if sentence in  result:\n",
        "        candiates_for_summary += \" \"+ sentence\n",
        "    \n",
        "    # Get the sentences in their original order in the text\n",
        "    summary = \"\"\n",
        "    for sentence in list_of_sentences:\n",
        "      if sentence in candiates_for_summary:\n",
        "          summary += \" \" + sentence  \n",
        "         \n",
        "    \n",
        "    print(\"Number of words-- summary vs text: \", len(summary.split()), '/', len(text.split()))\n",
        "    print(\"Number of sentences-- summary vs text: \", len(sent_tokenize(summary)), '/', len(sent_tokenize(text)))\n",
        "    return summary\n",
        "     \n",
        "  ## Execute the function to generate the summarization of the given text\n",
        "  summary = summary(list_of_sentences, sentence_score_table)\n",
        "\n",
        "  return summary\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}