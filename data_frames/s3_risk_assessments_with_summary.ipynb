{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "risk_assessments_with_summary.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfsVYzP+xLGV7g870WP2Re",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deregenboogm/NLP_coronavirus_project/blob/master/data_frames/risk_assessments_with_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ2_H2wAlv9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_risk_reports():\n",
        "  ## Define url\n",
        "  url = \"https://www.ecdc.europa.eu/en/taxonomy/term/1295/feed\"\n",
        "\n",
        "  ## Request to access the url\n",
        "  r = requests.get(url)\n",
        "  \n",
        "  ## Parsing the content\n",
        "  soup = BeautifulSoup(r.content, features=\"xml\") \n",
        "\n",
        "  ## Find items in the content\n",
        "  items = soup.find_all(\"item\")\n",
        "\n",
        "  ## Optain a list of report items with their features  \n",
        "  news_items=[]\n",
        "     \n",
        "  for item in items:\n",
        "    if \"COVID\" in item.title.text:    ### searching in title text gives better results for related texts at this web-page\n",
        "      news_item = {}                     \n",
        "      news_item[\"title\"] = item.title.text\n",
        "      news_item[\"date\"] = item.pubDate.text\n",
        "      news_item[\"date\"] = pd.to_datetime(news_item[\"date\"])\n",
        "      news_item[\"date\"] = news_item[\"date\"].isoformat().split('T')[0]\n",
        "      news_item[\"link\"] =  item.link.text\n",
        "      news_item[\"description\"] = item.description.text\n",
        "      news_item[\"summary\"] = []\n",
        "      \n",
        "      ### Optain texts through accessing web links \n",
        "      for link in item.link:\n",
        "        res = requests.get(link)\n",
        "        soup = BeautifulSoup(res.content, \"html.parser\")\n",
        "\n",
        "        article = soup.find_all(\"div\", class_ = \"text-image\")\n",
        "\n",
        "        executive_summary = []\n",
        "              \n",
        "        for pr in article:\n",
        "          paragraphs = pr.find_all(\"p\")\n",
        "          for i in paragraphs:\n",
        "            joined_p = \"\".join(i.text)\n",
        "            joined_p = joined_p.replace(\".\", \". \")\n",
        "            joined_p = joined_p.replace(\" '\", \"'\")\n",
        "            executive_summary.append(joined_p)\n",
        "                        \n",
        "        executive_summary = ''.join(map(str, executive_summary))      \n",
        "\n",
        "        ##### Update each item dictionary through using the text summarization function that has been already created above\n",
        "        summ = generate_summary(executive_summary)\n",
        "        news_item[\"summary\"] = summ         \n",
        "      \n",
        "      ### Append each item dictionary to the general item list(results)\n",
        "      news_items.append(news_item)\n",
        "       \n",
        "  df = pd.DataFrame(news_items, index=None)\n",
        "\n",
        "  # Saving the dataframe table\n",
        "  df.to_csv(\"/content/drive/My Drive/Risk_assessment_reports.csv\", index = False)\n",
        "\n",
        "  print(\"Total number of COVID-19 risk assessment repots: \" , len(news_items))\n",
        "  print(\"The 'Risk_assessment_reports.csv' file has been successfully updated for today!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
